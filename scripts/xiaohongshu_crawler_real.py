#!/usr/bin/env python3
"""
å°çº¢ä¹¦æµè¡Œç—…è¯æ¡çœŸå®æ•°æ®é‡‡é›†è„šæœ¬
ä½¿ç”¨Playwright + Cookieç™»å½•æ–¹å¼
"""

import json
import time
import random
from datetime import datetime
from pathlib import Path

# å°è¯•å¯¼å…¥playwright
try:
    from playwright.sync_api import sync_playwright
    PLAYWRIGHT_AVAILABLE = True
except ImportError:
    PLAYWRIGHT_AVAILABLE = False
    print("âš ï¸ Playwrightæœªå®‰è£…ï¼Œä½¿ç”¨requestsæ–¹å¼")

# é…ç½®
COOKIE_FILE = "/root/.openclaw/workspace/config/xiaohongshu_cookie.txt"
OUTPUT_DIR = "/root/.openclaw/workspace/knowledge/xiaohongshu_epidemic/raw"
Path(OUTPUT_DIR).mkdir(parents=True, exist_ok=True)

# å‘¼å¸ç³»ç»Ÿå…³é”®è¯åˆ—è¡¨ï¼ˆP0ä¼˜å…ˆçº§ï¼‰
KEYWORDS_P0 = [
    "è¿‡æ•æ€§é¼»ç‚",
    "èŠ±ç²‰è¿‡æ•", 
    "å“®å–˜",
    "æµæ„Ÿ",
    "ç”²æµ",
    "æ”¯åŸä½“è‚ºç‚"
]

# æ›´å¤šå‘¼å¸ç³»ç»Ÿå…³é”®è¯ï¼ˆP1ä¼˜å…ˆçº§ï¼‰
KEYWORDS_P1 = [
    "å’³å—½å˜å¼‚æ€§å“®å–˜",
    "é¼»çª¦ç‚",
    "é¼»ç—…æ¯’",
    "ä¹™æµ",
    "å‘¼å¸é“åˆèƒç—…æ¯’",
    "è…ºç—…æ¯’",
    "æ…¢æ€§å’½ç‚",
    "æ‰æ¡ƒä½“ç‚"
]

def load_cookies():
    """åŠ è½½Cookie"""
    with open(COOKIE_FILE, 'r') as f:
        cookie_str = f.read().strip()
    
    cookies = []
    for item in cookie_str.split(';'):
        item = item.strip()
        if '=' in item:
            name, value = item.split('=', 1)
            cookies.append({
                'name': name,
                'value': value,
                'domain': '.xiaohongshu.com',
                'path': '/'
            })
    return cookies

def crawl_with_playwright(keyword, max_notes=100):
    """ä½¿ç”¨Playwrightçˆ¬å–å°çº¢ä¹¦æ•°æ®"""
    if not PLAYWRIGHT_AVAILABLE:
        return None
    
    results = []
    
    with sync_playwright() as p:
        browser = p.chromium.launch(headless=True)
        context = browser.new_context(
            viewport={'width': 1920, 'height': 1080},
            user_agent='Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'
        )
        
        # æ·»åŠ Cookie
        cookies = load_cookies()
        context.add_cookies(cookies)
        
        page = context.new_page()
        
        try:
            # è®¿é—®æœç´¢é¡µé¢
            search_url = f"https://www.xiaohongshu.com/search_result?keyword={keyword}&type=51"
            print(f"ğŸ” æ­£åœ¨æœç´¢: {keyword}")
            page.goto(search_url, wait_until='networkidle', timeout=60000)
            
            # ç­‰å¾…å†…å®¹åŠ è½½
            time.sleep(3)
            
            # æ»šåŠ¨åŠ è½½æ›´å¤šå†…å®¹
            for i in range(5):
                page.evaluate('window.scrollTo(0, document.body.scrollHeight)')
                time.sleep(2)
                print(f"  æ»šåŠ¨åŠ è½½... {i+1}/5")
            
            # æå–ç¬”è®°æ•°æ®
            notes = page.evaluate('''() => {
                const items = document.querySelectorAll('[data-testid="note-item"]');
                const data = [];
                items.forEach(item => {
                    const titleEl = item.querySelector('.title');
                    const authorEl = item.querySelector('.author');
                    const likeEl = item.querySelector('.like-count');
                    
                    if (titleEl) {
                        data.push({
                            title: titleEl.textContent?.trim() || '',
                            author: authorEl?.textContent?.trim() || '',
                            likes: likeEl?.textContent?.trim() || '0'
                        });
                    }
                });
                return data;
            }''')
            
            results = notes[:max_notes]
            print(f"âœ… æˆåŠŸè·å– {len(results)} æ¡ç¬”è®°")
            
        except Exception as e:
            print(f"âŒ çˆ¬å–å¤±è´¥: {e}")
        finally:
            browser.close()
    
    return results

def save_results(keyword, results):
    """ä¿å­˜ç»“æœåˆ°JSONæ–‡ä»¶"""
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    filename = f"{keyword}_{timestamp}_{len(results)}.json"
    filepath = Path(OUTPUT_DIR) / filename
    
    data = {
        'keyword': keyword,
        'crawl_time': datetime.now().isoformat(),
        'total_count': len(results),
        'notes': results
    }
    
    with open(filepath, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    
    print(f"ğŸ’¾ æ•°æ®å·²ä¿å­˜: {filepath}")
    return filepath

def main():
    """ä¸»å‡½æ•°"""
    print("="*60)
    print("å°çº¢ä¹¦æµè¡Œç—…è¯æ¡æ•°æ®é‡‡é›†")
    print("="*60)
    
    # æ£€æŸ¥Cookie
    if not Path(COOKIE_FILE).exists():
        print(f"âŒ Cookieæ–‡ä»¶ä¸å­˜åœ¨: {COOKIE_FILE}")
        return
    
    print(f"âœ… Cookieæ–‡ä»¶å·²åŠ è½½")
    
    # å…ˆé‡‡é›†P0å…³é”®è¯
    print(f"\nğŸ¯ å¼€å§‹é‡‡é›†P0ä¼˜å…ˆçº§å…³é”®è¯ï¼ˆå…±{len(KEYWORDS_P0)}ä¸ªï¼‰")
    
    for i, keyword in enumerate(KEYWORDS_P0, 1):
        print(f"\n[{i}/{len(KEYWORDS_P0)}] {keyword}")
        print("-"*40)
        
        if PLAYWRIGHT_AVAILABLE:
            results = crawl_with_playwright(keyword, max_notes=100)
            if results:
                save_results(keyword, results)
        else:
            print("âš ï¸ Playwrightæœªå®‰è£…ï¼Œè·³è¿‡çœŸå®çˆ¬å–")
        
        # éšæœºå»¶è¿Ÿï¼Œé¿å…è¢«å°
        delay = random.uniform(3, 6)
        print(f"â³ ç­‰å¾… {delay:.1f} ç§’...")
        time.sleep(delay)
    
    print("\n" + "="*60)
    print("âœ… P0å…³é”®è¯é‡‡é›†å®Œæˆ")
    print("="*60)

if __name__ == '__main__':
    main()
