#!/usr/bin/env python3
"""
å¾®åšçƒ­æœè·å–è„šæœ¬ - ä½¿ç”¨ Cookie è®¤è¯
ç­›é€‰å¥åº·ç›¸å…³è¯é¢˜ï¼Œæ’é™¤å¨±ä¹/ç»¼è‰ºè¯¯åŒ¹é…
"""

import requests
import re
import json
import sys
from datetime import datetime
from urllib.parse import unquote

# å¥åº·ç›¸å…³å…³é”®è¯
HEALTH_KEYWORDS = [
    'å¥åº·', 'åŒ»ç–—', 'åŒ»é™¢', 'åŒ»ç”Ÿ', 'ç–¾ç—…', 'ç—…ç—‡', 'ç—‡çŠ¶', 'æ²»ç–—', 'æ‰‹æœ¯',
    'å…»ç”Ÿ', 'ä¿å¥', 'è¥å…»', 'é¥®é£Ÿ', 'å‡è‚¥', 'å¥èº«', 'è¿åŠ¨', 'ç¡çœ ', 'å¿ƒç†',
    'ç™Œç—‡', 'è‚¿ç˜¤', 'ç³–å°¿ç—…', 'é«˜è¡€å‹', 'å¿ƒè„ç—…', 'æ„Ÿå†’', 'å‘çƒ§', 'æµæ„Ÿ',
    'ç–«è‹—', 'æ¥ç§', 'è¿‡æ•', 'é¼»ç‚', 'å“®å–˜', 'è¿‘è§†', 'çœ¼ç§‘', 'ç‰™ç§‘', 'å£è…”',
    'ä½“æ£€', 'æ£€æŸ¥', 'è¯Šæ–­', 'è¯ç‰©', 'è¯å“', 'ä¸­åŒ»', 'è¥¿åŒ»', 'æŠ¤ç†', 'åº·å¤',
    'æ–°å† ', 'ç—…æ¯’', 'æ„ŸæŸ“', 'ä¼ æŸ“', 'å…ç–«åŠ›', 'ç»´ç”Ÿç´ ', 'è›‹ç™½', 'è„‚è‚ª', 'ç³–',
    'çŒæ­»', 'æ€¥æ•‘', 'åŒ»ä¿', 'åŒ»è¯', 'å«ç”Ÿ', 'å£ç½©', 'é˜²æŠ¤', 'æ¶ˆæ¯’', 'æ€èŒ',
    'æŠ‘éƒ', 'ç„¦è™‘', 'ç²¾ç¥', 'å¤±çœ ', 'å¤´ç—›', 'èƒƒç—›', 'å’³å—½', 'å‘çƒ§', 'å‘çƒ­',
    'å«å¥å§”', 'æ€¥æ•‘ä¸­å¿ƒ', 'ç»“çŸ³', 'è‚¾', 'è‚', 'èƒƒ', 'è‚º', 'å¿ƒ', 'è„‘', 'è¡€',
    'å­•', 'èƒ', 'å©´', 'å„¿', 'è€', 'ç—…', 'ç—›', 'è¯', 'è¯Š', 'ç–—'
]

# æ’é™¤å…³é”®è¯ï¼ˆå¨±ä¹/ç»¼è‰ºç­‰ï¼‰
EXCLUDE_KEYWORDS = [
    'æ‹ç»¼', 'ç»¼è‰º', 'ç”µè§†å‰§', 'ç”µå½±', 'æ˜æ˜Ÿ', 'æ¼”å‘˜', 'æ­Œæ‰‹', 'å¶åƒ',
    'CP', 'æ‹çˆ±', 'åˆ†æ‰‹', 'ç»“å©š', 'ç¦»å©š', 'å‡ºè½¨', 'çˆ†æ–™', 'è·¯é€',
    'ç›´æ’­', 'ç½‘çº¢', 'ä¸»æ’­', 'ç²‰ä¸', 'åº”æ´', 'æ‰“æ¦œ', 'æŠ•ç¥¨', 'é€‰ç§€'
]

def load_cookie():
    """ä»æ–‡ä»¶åŠ è½½ Cookie"""
    try:
        with open('/root/.openclaw/workspace/config/weibo_cookie.txt', 'r') as f:
            return f.read().strip()
    except Exception as e:
        print(f"è¯»å– Cookie å¤±è´¥: {e}")
        return None

def fetch_weibo_hotsearch():
    """è·å–å¾®åšçƒ­æœæ¦œ"""
    cookie = load_cookie()
    if not cookie:
        return None
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Cookie': cookie,
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
        'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
        'Referer': 'https://weibo.com/',
        'Connection': 'keep-alive',
    }
    
    try:
        session = requests.Session()
        session.headers.update(headers)
        
        url = 'https://s.weibo.com/top/summary?cate=realtimehot'
        response = session.get(url, timeout=15, allow_redirects=True)
        response.encoding = 'utf-8'
        
        if 'passport.weibo.com' in response.url:
            print("Cookie å·²å¤±æ•ˆæˆ–éœ€è¦é‡æ–°ç™»å½•")
            return None
        
        return response.text
    except Exception as e:
        print(f"è¯·æ±‚å¼‚å¸¸: {e}")
        return None

def parse_hotsearch(html):
    """è§£æçƒ­æœæ•°æ®"""
    if not html:
        return []
    
    hot_list = []
    
    # æ ¹æ®å®é™… HTML ç»“æ„è§£æ
    pattern = r'<tr[^>]*>\s*<td[^>]*class=["\']td-01[^"\']*["\'][^>]*>\s*(?:<i[^>]*>)?([^\s<]*)(?:</i>)?\s*</td>\s*<td[^>]*class=["\']td-02["\'][^>]*>\s*<a[^\u003e]*href=["\']([^"\']+)["\'][^\u003e]*target=["\']_blank["\'][^\u003e]*>([^\u003c]+)</a>\s*(?:<i[^>]*>[^\u003c]*</i>)?\s*(?:<span[^\u003e]*>([^\u003c]*)\u003c/span>)?\s*</td>'
    
    matches = re.findall(pattern, html, re.DOTALL)
    
    for match in matches:
        rank, link, title, hot_count = match
        rank = rank.strip()
        title = title.strip()
        hot_count = hot_count.strip() if hot_count else ''
        
        # å¤„ç†æ’åï¼ˆå¯èƒ½æ˜¯ "icon-top" æˆ–æ•°å­—ï¼‰
        if not rank or 'icon' in rank:
            rank = 'ç½®é¡¶'
        
        # ç¡®ä¿é“¾æ¥å®Œæ•´
        if link.startswith('/'):
            link = f'https://s.weibo.com{link}'
        elif not link.startswith('http'):
            link = f'https://s.weibo.com/weibo?q={link}'
        
        if title:
            hot_list.append({
                'rank': rank,
                'title': title,
                'link': link,
                'hot_count': hot_count
            })
    
    return hot_list

def filter_health_topics(hot_list):
    """ç­›é€‰å¥åº·ç›¸å…³è¯é¢˜ï¼Œæ’é™¤å¨±ä¹å†…å®¹"""
    health_topics = []
    
    for item in hot_list:
        title = item.get('title', '')
        hot_count = item.get('hot_count', '')
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«å¥åº·å…³é”®è¯
        is_health = False
        for keyword in HEALTH_KEYWORDS:
            if keyword in title:
                is_health = True
                break
        
        if not is_health:
            continue
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯å¨±ä¹å†…å®¹ï¼ˆæ ‡é¢˜æˆ–çƒ­åº¦æ ‡ç­¾ä¸­åŒ…å«ç»¼è‰ºç­‰å…³é”®è¯ï¼‰
        is_entertainment = False
        for exclude in EXCLUDE_KEYWORDS:
            if exclude in title or exclude in hot_count:
                is_entertainment = True
                break
        
        if not is_entertainment:
            health_topics.append(item)
    
    return health_topics

def format_output(health_topics, all_count=0):
    """æ ¼å¼åŒ–è¾“å‡º"""
    if not health_topics:
        return "æœ¬è½®æš‚æ— å¥åº·ç›¸å…³çƒ­æœ"
    
    now = datetime.now().strftime('%Y-%m-%d %H:%M')
    output = [f"ğŸ“Š å¾®åšå¥åº·çƒ­æœï¼ˆ{now}ï¼‰"]
    output.append(f"å…±ç›‘æµ‹ {all_count} æ¡çƒ­æœï¼Œå‘ç° {len(health_topics)} æ¡å¥åº·ç›¸å…³\n")
    
    for i, topic in enumerate(health_topics[:10], 1):
        output.append(f"{i}. #{topic['title']}#")
        output.append(f"   æ’åï¼šç¬¬{topic['rank']}ä½")
        output.append(f"   é“¾æ¥ï¼š{topic['link']}")
        if topic.get('hot_count'):
            output.append(f"   çƒ­åº¦ï¼š{topic['hot_count']}")
        output.append("")
    
    return '\n'.join(output)

def main():
    print("="*50)
    print("å¾®åšå¥åº·çƒ­æœç›‘æµ‹")
    print("="*50)
    
    html = fetch_weibo_hotsearch()
    
    if not html:
        print("\nâŒ è·å–å¤±è´¥ï¼ŒCookie å¯èƒ½å·²å¤±æ•ˆ")
        print("è¯·æ›´æ–° Cookie åé‡è¯•")
        sys.exit(1)
    
    print("\nè§£æçƒ­æœæ•°æ®...")
    hot_list = parse_hotsearch(html)
    
    if not hot_list:
        # ä¿å­˜ HTML ç”¨äºè°ƒè¯•
        debug_file = '/root/.openclaw/workspace/data/weibo_debug.html'
        with open(debug_file, 'w', encoding='utf-8') as f:
            f.write(html[:50000])
        print(f"æœªè§£æåˆ°çƒ­æœæ•°æ®ï¼ŒHTML å·²ä¿å­˜åˆ°: {debug_file}")
    
    print(f"å…±è·å– {len(hot_list)} æ¡çƒ­æœ")
    
    health_topics = filter_health_topics(hot_list)
    print(f"æ‰¾åˆ° {len(health_topics)} æ¡å¥åº·ç›¸å…³çƒ­æœ")
    
    output = format_output(health_topics, len(hot_list))
    print("\n" + "="*50)
    print(output)
    print("="*50)
    
    # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
    result_file = '/root/.openclaw/workspace/data/weibo_health_hotsearch.txt'
    with open(result_file, 'w', encoding='utf-8') as f:
        f.write(output)
    print(f"\nâœ… ç»“æœå·²ä¿å­˜åˆ°: {result_file}")

if __name__ == '__main__':
    main()
