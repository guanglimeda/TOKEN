#!/usr/bin/env python3
"""
å¾®åšå¥åº·çƒ­æœç›‘æµ‹è„šæœ¬ - æ¯å°æ—¶æ‰§è¡Œ
åŠŸèƒ½ï¼š
1. çˆ¬å–å¾®åšçƒ­æœ
2. ç­›é€‰å¥åº·ç›¸å…³è¯é¢˜
3. å‘é€åˆ°é’‰é’‰ç¾¤
4. è®°å½•åˆ°çŸ¥è¯†åº“
"""

import requests
import re
import json
import sys
import os
from datetime import datetime
from urllib.parse import unquote

# å¥åº·ç›¸å…³å…³é”®è¯
HEALTH_KEYWORDS = [
    'å¥åº·', 'åŒ»ç–—', 'åŒ»é™¢', 'åŒ»ç”Ÿ', 'ç–¾ç—…', 'ç—…ç—‡', 'ç—‡çŠ¶', 'æ²»ç–—', 'æ‰‹æœ¯',
    'å…»ç”Ÿ', 'ä¿å¥', 'è¥å…»', 'é¥®é£Ÿ', 'å‡è‚¥', 'å¥èº«', 'è¿åŠ¨', 'ç¡çœ ', 'å¿ƒç†',
    'ç™Œç—‡', 'è‚¿ç˜¤', 'ç³–å°¿ç—…', 'é«˜è¡€å‹', 'å¿ƒè„ç—…', 'æ„Ÿå†’', 'å‘çƒ§', 'æµæ„Ÿ',
    'ç–«è‹—', 'æ¥ç§', 'è¿‡æ•', 'é¼»ç‚', 'å“®å–˜', 'è¿‘è§†', 'çœ¼ç§‘', 'ç‰™ç§‘', 'å£è…”',
    'ä½“æ£€', 'æ£€æŸ¥', 'è¯Šæ–­', 'è¯ç‰©', 'è¯å“', 'ä¸­åŒ»', 'è¥¿åŒ»', 'æŠ¤ç†', 'åº·å¤',
    'æ–°å† ', 'ç—…æ¯’', 'æ„ŸæŸ“', 'ä¼ æŸ“', 'å…ç–«åŠ›', 'ç»´ç”Ÿç´ ', 'è›‹ç™½', 'è„‚è‚ª', 'ç³–',
    'çŒæ­»', 'æ€¥æ•‘', 'åŒ»ä¿', 'åŒ»è¯', 'å«ç”Ÿ', 'å£ç½©', 'é˜²æŠ¤', 'æ¶ˆæ¯’', 'æ€èŒ',
    'æŠ‘éƒ', 'ç„¦è™‘', 'ç²¾ç¥', 'å¤±çœ ', 'å¤´ç—›', 'èƒƒç—›', 'å’³å—½', 'å‘çƒ§', 'å‘çƒ­',
    'å«å¥å§”', 'æ€¥æ•‘ä¸­å¿ƒ', 'ç»“çŸ³', 'è‚¾', 'è‚', 'èƒƒ', 'è‚º', 'å¿ƒ', 'è„‘', 'è¡€',
    'å­•', 'èƒ', 'å©´', 'å„¿', 'è€', 'ç—…', 'ç—›', 'è¯', 'è¯Š', 'ç–—'
]

# æ’é™¤å…³é”®è¯ï¼ˆå¨±ä¹/ç»¼è‰ºç­‰ï¼‰
EXCLUDE_KEYWORDS = [
    'æ‹ç»¼', 'ç»¼è‰º', 'ç”µè§†å‰§', 'ç”µå½±', 'æ˜æ˜Ÿ', 'æ¼”å‘˜', 'æ­Œæ‰‹', 'å¶åƒ',
    'CP', 'æ‹çˆ±', 'åˆ†æ‰‹', 'ç»“å©š', 'ç¦»å©š', 'å‡ºè½¨', 'çˆ†æ–™', 'è·¯é€',
    'ç›´æ’­', 'ç½‘çº¢', 'ä¸»æ’­', 'ç²‰ä¸', 'åº”æ´', 'æ‰“æ¦œ', 'æŠ•ç¥¨', 'é€‰ç§€'
]

def load_cookie():
    """ä»æ–‡ä»¶åŠ è½½ Cookie"""
    try:
        with open('/root/.openclaw/workspace/config/weibo_cookie.txt', 'r') as f:
            return f.read().strip()
    except Exception as e:
        print(f"è¯»å– Cookie å¤±è´¥: {e}")
        return None

def fetch_weibo_hotsearch():
    """è·å–å¾®åšçƒ­æœæ¦œ"""
    cookie = load_cookie()
    if not cookie:
        return None
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Cookie': cookie,
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
        'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
        'Referer': 'https://weibo.com/',
        'Connection': 'keep-alive',
    }
    
    try:
        session = requests.Session()
        session.headers.update(headers)
        
        url = 'https://s.weibo.com/top/summary?cate=realtimehot'
        response = session.get(url, timeout=15, allow_redirects=True)
        response.encoding = 'utf-8'
        
        if 'passport.weibo.com' in response.url:
            print("Cookie å·²å¤±æ•ˆæˆ–éœ€è¦é‡æ–°ç™»å½•")
            return None
        
        return response.text
    except Exception as e:
        print(f"è¯·æ±‚å¼‚å¸¸: {e}")
        return None

def parse_hotsearch(html):
    """è§£æçƒ­æœæ•°æ®"""
    if not html:
        return []
    
    hot_list = []
    
    # æ ¹æ®å®é™… HTML ç»“æ„è§£æ
    pattern = r'<tr[^>]*>\s*<td[^>]*class=["\']td-01[^"\']*["\'][^>]*>\s*(?:<i[^>]*>)?([^\s<]*)(?:</i>)?\s*</td>\s*<td[^>]*class=["\']td-02["\'][^>]*>\s*<a[^\u003e]*href=["\']([^"\']+)["\'][^\u003e]*target=["\']_blank["\'][^\u003e]*>([^\u003c]+)</a>\s*(?:<i[^>]*>[^\u003c]*</i>)?\s*(?:<span[^\u003e]*>([^\u003c]*)\u003c/span>)?\s*</td>'
    
    matches = re.findall(pattern, html, re.DOTALL)
    
    for match in matches:
        rank, link, title, hot_count = match
        rank = rank.strip()
        title = title.strip()
        hot_count = hot_count.strip() if hot_count else ''
        
        # å¤„ç†æ’åï¼ˆå¯èƒ½æ˜¯ "icon-top" æˆ–æ•°å­—ï¼‰
        if not rank or 'icon' in rank:
            rank = 'ç½®é¡¶'
        
        # ç¡®ä¿é“¾æ¥å®Œæ•´
        if link.startswith('/'):
            link = f'https://s.weibo.com{link}'
        elif not link.startswith('http'):
            link = f'https://s.weibo.com/weibo?q={link}'
        
        if title:
            hot_list.append({
                'rank': rank,
                'title': title,
                'link': link,
                'hot_count': hot_count
            })
    
    return hot_list

def filter_health_topics(hot_list):
    """ç­›é€‰å¥åº·ç›¸å…³è¯é¢˜ï¼Œæ’é™¤å¨±ä¹å†…å®¹"""
    health_topics = []
    
    for item in hot_list:
        title = item.get('title', '')
        hot_count = item.get('hot_count', '')
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«å¥åº·å…³é”®è¯
        is_health = False
        for keyword in HEALTH_KEYWORDS:
            if keyword in title:
                is_health = True
                break
        
        if not is_health:
            continue
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯å¨±ä¹å†…å®¹
        is_entertainment = False
        for exclude in EXCLUDE_KEYWORDS:
            if exclude in title or exclude in hot_count:
                is_entertainment = True
                break
        
        if not is_entertainment:
            health_topics.append(item)
    
    return health_topics

def save_to_knowledge_base(health_topics):
    """ä¿å­˜åˆ°çŸ¥è¯†åº“"""
    if not health_topics:
        return
    
    now = datetime.now()
    date_str = now.strftime('%Y-%m-%d')
    time_str = now.strftime('%H:%M')
    timestamp = now.strftime('%Y-%m-%d %H:%M:%S')
    
    # ç¡®ä¿çŸ¥è¯†åº“ç›®å½•å­˜åœ¨
    kb_dir = '/root/.openclaw/workspace/knowledge/weibo_hotsearch'
    os.makedirs(kb_dir, exist_ok=True)
    
    # æŒ‰æ—¥æœŸå­˜å‚¨
    kb_file = f'{kb_dir}/{date_str}.md'
    
    # è¯»å–ç°æœ‰å†…å®¹
    existing_content = ""
    if os.path.exists(kb_file):
        with open(kb_file, 'r', encoding='utf-8') as f:
            existing_content = f.read()
    
    # æ„å»ºæ–°è®°å½•
    new_records = []
    new_records.append(f"\n## {time_str} å¥åº·çƒ­æœ\n")
    new_records.append(f"**é‡‡é›†æ—¶é—´**: {timestamp}\n")
    new_records.append("| æ’å | è¯é¢˜ | é“¾æ¥ | çƒ­åº¦ |")
    new_records.append("|------|------|------|------|")
    
    for topic in health_topics:
        rank = topic['rank']
        title = topic['title']
        link = topic['link']
        hot = topic.get('hot_count', '')
        new_records.append(f"| {rank} | {title} | [{link}]({link}) | {hot} |")
    
    new_content = '\n'.join(new_records)
    
    # å¦‚æœæ˜¯æ–°æ–‡ä»¶ï¼Œæ·»åŠ æ ‡é¢˜
    if not existing_content:
        existing_content = f"# å¾®åšå¥åº·çƒ­æœè®°å½• - {date_str}\n"
    
    # è¿½åŠ æ–°è®°å½•
    with open(kb_file, 'w', encoding='utf-8') as f:
        f.write(existing_content + new_content + '\n')
    
    print(f"âœ… å·²è®°å½•åˆ°çŸ¥è¯†åº“: {kb_file}")
    return kb_file

def format_dingtalk_message(health_topics, all_count=0):
    """æ ¼å¼åŒ–é’‰é’‰æ¶ˆæ¯"""
    if not health_topics:
        return None
    
    now = datetime.now().strftime('%Y-%m-%d %H:%M')
    
    lines = [f"ğŸ“Š å¾®åšå¥åº·çƒ­æœï¼ˆ{now}ï¼‰\n"]
    lines.append(f"å…±ç›‘æµ‹ {all_count} æ¡çƒ­æœï¼Œå‘ç° {len(health_topics)} æ¡å¥åº·ç›¸å…³\n")
    
    for i, topic in enumerate(health_topics[:10], 1):
        lines.append(f"{i}. #{topic['title']}#")
        lines.append(f"   æ’åï¼šç¬¬{topic['rank']}ä½")
        lines.append(f"   é“¾æ¥ï¼š{topic['link']}")
        if topic.get('hot_count'):
            lines.append(f"   çƒ­åº¦ï¼š{topic['hot_count']}")
        lines.append("")
    
    return '\n'.join(lines)

def send_to_dingtalk(message):
    """å‘é€åˆ°é’‰é’‰ç¾¤"""
    if not message:
        return
    
    # ä½¿ç”¨ OpenClaw çš„æ¶ˆæ¯å‘é€æœºåˆ¶
    # è¿™é‡Œé€šè¿‡å†™å…¥æ–‡ä»¶ï¼Œç”±è°ƒç”¨è€…å¤„ç†å‘é€
    msg_file = '/root/.openclaw/workspace/data/last_hotsearch_message.txt'
    with open(msg_file, 'w', encoding='utf-8') as f:
        f.write(message)
    print(f"âœ… æ¶ˆæ¯å·²å‡†å¤‡: {msg_file}")

def main():
    print("="*60)
    print("å¾®åšå¥åº·çƒ­æœç›‘æµ‹ä»»åŠ¡")
    print(f"æ‰§è¡Œæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("="*60)
    
    # 1. è·å–çƒ­æœ
    html = fetch_weibo_hotsearch()
    if not html:
        print("\nâŒ è·å–å¤±è´¥ï¼ŒCookie å¯èƒ½å·²å¤±æ•ˆ")
        # è®°å½•å¤±è´¥æ—¥å¿—
        log_file = '/root/.openclaw/workspace/data/hotsearch_error.log'
        with open(log_file, 'a', encoding='utf-8') as f:
            f.write(f"{datetime.now().strftime('%Y-%m-%d %H:%M:%S')} - Cookieå¤±æ•ˆ\n")
        sys.exit(1)
    
    # 2. è§£ææ•°æ®
    print("\nè§£æçƒ­æœæ•°æ®...")
    hot_list = parse_hotsearch(html)
    print(f"å…±è·å– {len(hot_list)} æ¡çƒ­æœ")
    
    # 3. ç­›é€‰å¥åº·è¯é¢˜
    health_topics = filter_health_topics(hot_list)
    print(f"æ‰¾åˆ° {len(health_topics)} æ¡å¥åº·ç›¸å…³çƒ­æœ")
    
    # 4. è®°å½•åˆ°çŸ¥è¯†åº“
    if health_topics:
        kb_file = save_to_knowledge_base(health_topics)
    
    # 5. å‡†å¤‡é’‰é’‰æ¶ˆæ¯
    message = format_dingtalk_message(health_topics, len(hot_list))
    if message:
        send_to_dingtalk(message)
        print("\n" + "="*60)
        print(message)
        print("="*60)
    else:
        print("\næœ¬è½®æš‚æ— å¥åº·ç›¸å…³çƒ­æœ")
    
    # 6. ä¿å­˜åŸå§‹æ•°æ®
    raw_data = {
        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        'total': len(hot_list),
        'health_count': len(health_topics),
        'health_topics': health_topics
    }
    raw_file = f"/root/.openclaw/workspace/data/raw_hotsearch_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    with open(raw_file, 'w', encoding='utf-8') as f:
        json.dump(raw_data, f, ensure_ascii=False, indent=2)
    
    print(f"\nâœ… ä»»åŠ¡å®Œæˆ")
    print(f"   - åŸå§‹æ•°æ®: {raw_file}")
    if health_topics:
        print(f"   - çŸ¥è¯†åº“: {kb_file}")

if __name__ == '__main__':
    main()
